import json

# Charger le notebook
with open('ALPHABOT_ML_TRAINING_COLAB.ipynb', 'r', encoding='utf-8') as f:
    nb = json.load(f)

# Trouver et corriger la cellule 5 pour restaurer le mod√®le GPU
for cell in nb['cells']:
    if cell['cell_type'] == 'code' and 'CELLULE 5: Entra√Ænement Pattern Detector' in ''.join(cell['source']):
        source = cell['source']
        
        # Remplacer par un mod√®le GPU optimis√© pour A100
        new_gpu_section = [
            "# Cr√©er le mod√®le GPU optimis√© pour A100\n",
            "print(\"üîß Cr√©ation du mod√®le GPU optimis√© pour A100...\")\n",
            "\n",
            "# V√©rifier la disponibilit√© du GPU\n",
            "print(f\"üìä GPU disponible: {tf.config.list_physical_devices('GPU')}\")\n",
            "print(f\"üìä Strat√©gie de distribution: {strategy}\")\n",
            "\n",
            "# Configuration optimis√©e pour A100\n",
            "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
            "\n",
            "with strategy.scope():\n",
            "    # Utiliser un mod√®le LSTM/CNN hybride optimis√© pour GPU\n",
            "    inputs = tf.keras.Input(shape=(30, 3), name='input_layer', dtype=tf.float32)\n",
            "    \n",
            "    # Normalisation des entr√©es\n",
            "    x = tf.keras.layers.BatchNormalization()(inputs)\n",
            "    \n",
            "    # Couches LSTM bidirectionnelles pour meilleure performance\n",
            "    x = tf.keras.layers.Bidirectional(\n",
            "        tf.keras.layers.LSTM(\n",
            "            64, \n",
            "            return_sequences=True,\n",
            "            kernel_initializer='glorot_uniform',\n",
            "            recurrent_initializer='orthogonal',\n",
            "            bias_initializer='zeros',\n",
            "            dropout=0.2,\n",
            "            recurrent_dropout=0.2,\n",
            "            name='lstm_bidirectional_1'\n",
            "        )\n",
            "    )(x)\n",
            "    \n",
            "    # Couche CNN 1D pour extraire des patterns locaux\n",
            "    x = tf.keras.layers.Conv1D(\n",
            "        filters=32, \n",
            "        kernel_size=3, \n",
            "        activation='relu',\n",
            "        padding='same',\n",
            "        name='conv1d_1'\n",
            "    )(x)\n",
            "    x = tf.keras.layers.MaxPooling1D(pool_size=2, name='maxpool_1')(x)\n",
            "    x = tf.keras.layers.Dropout(0.3, name='dropout_1')(x)\n",
            "    \n",
            "    # Deuxi√®me couche LSTM\n",
            "    x = tf.keras.layers.LSTM(\n",
            "        32, \n",
            "        return_sequences=False,\n",
            "        kernel_initializer='glorot_uniform',\n",
            "        recurrent_initializer='orthogonal',\n",
            "        bias_initializer='zeros',\n",
            "        dropout=0.2,\n",
            "        recurrent_dropout=0.2,\n",
            "        name='lstm_2'\n",
            "    )(x)\n",
            "    \n",
            "    # Couches denses\n",
            "    x = tf.keras.layers.Dense(64, activation='relu', name='dense_1')(x)\n",
            "    x = tf.keras.layers.BatchNormalization(name='batch_norm_1')(x)\n",
            "    x = tf.keras.layers.Dropout(0.4, name='dropout_2')(x)\n",
            "    \n",
            "    x = tf.keras.layers.Dense(32, activation='relu', name='dense_2')(x)\n",
            "    x = tf.keras.layers.BatchNormalization(name='batch_norm_2')(x)\n",
            "    x = tf.keras.layers.Dropout(0.3, name='dropout_3')(x)\n",
            "    \n",
            "    # Couche de sortie avec dtype float32 pour stabilit√©\n",
            "    outputs = tf.keras.layers.Dense(3, activation='softmax', dtype=tf.float32, name='output')(x)\n",
            "    \n",
            "    # Cr√©er le mod√®le\n",
            "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='gpu_lstm_cnn_pattern_detector')\n",
            "    \n",
            "    # Compiler avec optimiseur adapt√© au GPU\n",
            "    model.compile(\n",
            "        optimizer=tf.keras.optimizers.AdamW(\n",
            "            learning_rate=0.001,\n",
            "            weight_decay=0.01,\n",
            "            clipnorm=1.0\n",
            "        ),\n",
            "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
            "        metrics=[\n",
            "            'accuracy',\n",
            "            tf.keras.metrics.SparseTopKCategoricalAccuracy(k=2, name='top_2_accuracy')\n",
            "        ]\n",
            "    )\n",
            "\n",
            "# Afficher le r√©sum√© du mod√®le\n",
            "print(\"‚úÖ Mod√®le GPU optimis√© cr√©√©:\")\n",
            "model.summary()\n",
            "\n",
            "# Callbacks avanc√©s pour GPU\n",
            "callbacks = [\n",
            "    tf.keras.callbacks.EarlyStopping(\n",
            "        patience=15, \n",
            "        restore_best_weights=True,\n",
            "        monitor='val_accuracy',\n",
            "        mode='max',\n",
            "        verbose=1,\n",
            "        start_from_epoch=10\n",
            "    ),\n",
            "    tf.keras.callbacks.ReduceLROnPlateau(\n",
            "        factor=0.5, \n",
            "        patience=8, \n",
            "        monitor='val_loss',\n",
            "        min_lr=1e-6,\n",
            "        verbose=1\n",
            "    ),\n",
            "    tf.keras.callbacks.ModelCheckpoint(\n",
            "        f'{base_path}/checkpoints/gpu_pattern_best.keras',\n",
            "        save_best_only=True,\n",
            "        monitor='val_accuracy',\n",
            "        mode='max',\n",
            "        save_weights_only=False\n",
            "    ),\n",
            "    tf.keras.callbacks.TensorBoard(\n",
            "        log_dir=f'{base_path}/logs/tensorboard',\n",
            "        histogram_freq=1,\n",
            "        update_freq='epoch'\n",
            "    )\n",
            "]\n",
            "\n",
            "# V√©rifier et pr√©parer les donn√©es\n",
            "print(f\"üìä V√©rification des donn√©es:\")\n",
            "print(f\"  - X_train shape: {X_train.shape}\")\n",
            "print(f\"  - y_train shape: {y_train.shape}\")\n",
            "print(f\"  - X_train dtype: {X_train.dtype}\")\n",
            "print(f\"  - y_train dtype: {y_train.dtype}\")\n",
            "print(f\"  - Valeurs uniques dans y_train: {np.unique(y_train)}\")\n",
            "\n",
            "# S'assurer que les donn√©es sont du bon type pour GPU\n",
            "X_train = X_train.astype(np.float32)\n",
            "y_train = y_train.astype(np.int32)\n",
            "\n",
            "# Normaliser les donn√©es pour GPU\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "scaler = StandardScaler()\n",
            "X_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
            "\n",
            "# Cr√©er un dataset TensorFlow optimis√© pour GPU\n",
            "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train))\n",
            "train_dataset = train_dataset.shuffle(buffer_size=len(X_train))\n",
            "train_dataset = train_dataset.batch(64)  # Batch size plus grand pour GPU\n",
            "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
            "\n",
            "# Split validation\n",
            "val_size = int(0.2 * len(X_train))\n",
            "val_dataset = train_dataset.take(val_size)\n",
            "train_dataset = train_dataset.skip(val_size)\n",
            "\n",
            "# Entra√Æner avec des param√®tres optimis√©s pour A100\n",
            "print(\"üöÄ D√©but de l'entra√Ænement GPU optimis√© pour A100...\")\n",
            "try:\n",
            "    history = model.fit(\n",
            "        train_dataset,\n",
            "        validation_data=val_dataset,\n",
            "        epochs=50,\n",
            "        callbacks=callbacks,\n",
            "        verbose=1,\n",
            "        steps_per_epoch=len(X_train) // 64\n",
            "    )\n",
            "    print(\"‚úÖ Entra√Ænement GPU termin√© avec succ√®s\")\n",
            "    \n",
            "    # Sauvegarder le mod√®le et le scaler\n",
            "    try:\n",
            "        model.save(f'{base_path}/models/gpu_lstm_cnn_model.keras')\n",
            "        import pickle\n",
            "        with open(f'{base_path}/models/gpu_scaler.pkl', 'wb') as f:\n",
            "            pickle.dump(scaler, f)\n",
            "        print(\"‚úÖ Mod√®le GPU et scaler sauvegard√©s\")\n",
            "    except Exception as e:\n",
            "        print(f\"‚ö†Ô∏è Erreur de sauvegarde: {e}\")\n",
            "    \n",
            "    # Afficher les courbes d'apprentissage\n",
            "    try:\n",
            "        plt.figure(figsize=(15, 5))\n",
            "        \n",
            "        plt.subplot(1, 3, 1)\n",
            "        plt.plot(history.history['accuracy'], label='Training')\n",
            "        if 'val_accuracy' in history.history:\n",
            "            plt.plot(history.history['val_accuracy'], label='Validation')\n",
            "        plt.title('Model Accuracy')\n",
            "        plt.legend()\n",
            "        \n",
            "        plt.subplot(1, 3, 2)\n",
            "        plt.plot(history.history['loss'], label='Training')\n",
            "        if 'val_loss' in history.history:\n",
            "            plt.plot(history.history['val_loss'], label='Validation')\n",
            "        plt.title('Model Loss')\n",
            "        plt.legend()\n",
            "        \n",
            "        if 'top_2_accuracy' in history.history:\n",
            "            plt.subplot(1, 3, 3)\n",
            "            plt.plot(history.history['top_2_accuracy'], label='Training Top-2')\n",
            "            if 'val_top_2_accuracy' in history.history:\n",
            "                plt.plot(history.history['val_top_2_accuracy'], label='Validation Top-2')\n",
            "            plt.title('Top-2 Accuracy')\n",
            "            plt.legend()\n",
            "        \n",
            "        plt.tight_layout()\n",
            "        plt.show()\n",
            "    except Exception as e:\n",
            "        print(f\"‚ö†Ô∏è Erreur lors de l'affichage des courbes: {e}\")\n",
            "        \n",
            "except Exception as e:\n",
            "    print(f\"‚ùå Erreur lors de l'entra√Ænement GPU: {e}\")\n",
            "    print(\"üîß Analyse de l'erreur:\")\n",
            "    print(f\"  - Type d'erreur: {type(e).__name__}\")\n",
            "    print(f\"  - Message: {str(e)}\")\n",
            "    \n",
            "    # Si erreur CuDNN, essayer une approche alternative\n",
            "    if \"CuDNN\" in str(e) or \"DNN\" in str(e):\n",
            "        print(\"üîß D√©tection d'erreur CuDNN, passage en mode CPU...\")\n",
            "        import os\n",
            "        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
            "        \n",
            "        # Recr√©er un mod√®le CPU simple\n",
            "        with tf.distribute.get_strategy().scope():\n",
            "            cpu_model = tf.keras.Sequential([\n",
            "                tf.keras.layers.Input(shape=(30, 3)),\n",
            "                tf.keras.layers.Flatten(),\n",
            "                tf.keras.layers.Dense(128, activation='relu'),\n",
            "                tf.keras.layers.Dropout(0.3),\n",
            "                tf.keras.layers.Dense(64, activation='relu'),\n",
            "                tf.keras.layers.Dropout(0.3),\n",
            "                tf.keras.layers.Dense(32, activation='relu'),\n",
            "                tf.keras.layers.Dense(3, activation='softmax')\n",
            "            ])\n",
            "            \n",
            "            cpu_model.compile(\n",
            "                optimizer='adam',\n",
            "                loss='sparse_categorical_crossentropy',\n",
            "                metrics=['accuracy']\n",
            "            )\n",
            "        \n",
            "        # Entra√Æner le mod√®le CPU\n",
            "        history = cpu_model.fit(\n",
            "            X_train_scaled, y_train,\n",
            "            epochs=20,\n",
            "            batch_size=32,\n",
            "            validation_split=0.2,\n",
            "            verbose=1\n",
            "        )\n",
            "        \n",
            "        model = cpu_model\n",
            "        print(\"‚úÖ Mod√®le CPU de secours entra√Æn√©\")\n",
            "    else:\n",
            "        raise e\n"
        ]
        
        # Trouver l'index o√π commencer le remplacement
        start_idx = None
        for i, line in enumerate(source):
            if "# Cr√©er un mod√®le compatible CPU (sans CuDNN)" in line:
                start_idx = i
                break
        
        if start_idx is not None:
            # Trouver la fin de la section √† remplacer
            end_idx = len(source)
            for i in range(start_idx, len(source)):
                if 'print("‚úÖ Mod√®le minimaliste entra√Æn√©")' in source[i]:
                    end_idx = i + 1
                    break
            
            # Remplacer la section
            source[start_idx:end_idx] = new_gpu_section
        
        break

# Sauvegarder le notebook corrig√©
with open('ALPHABOT_ML_TRAINING_COLAB.ipynb', 'w', encoding='utf-8') as f:
    json.dump(nb, f, indent=1, ensure_ascii=False)

print("Notebook corrig√© avec succ√®s - mod√®le GPU optimis√© pour A100 restaur√©!")
